# Outils Big Data - PySpark pour la Data Science

Ce r√©pertoire contient les livrables sous notebook Jupyter dans le cadre de la d√©couverte du module PySpark. Nous traiterons ainsi des concepts fondamentaux et avanc√©s de PySpark √† travers une base de donne√©s relatif √† Walmart qui sera d√©taill√© ci-dessous. 

## üìã **Table des mati√®res**

- [Structure du r√©pertoire](#structure-du-r√©pertoire)
- [Bases de donn√©es fournies par Walmart](#bases-de-donn√©es-fournies-par-walmart-)
- [Objectifs du projet](#objectifs-du-projet-)
- [D√©marches r√©alis√©es](#d√©marches-r√©alis√©es-)
- [Dataframe apr√®s manipulations](#dataframe-apr√®s-manipulations-)
- [Contact](#contact)

## **Structure du r√©pertoire**
```
.
    pyspark-data-science/
    ‚îú‚îÄ‚îÄ livrables/      # Notebooks des diff√©rentes √©tapes pour l'analyse de donn√©es
    ‚îî‚îÄ‚îÄ README.md       # Ce fichier
```

## **Bases de donn√©es fournies par Walmart** üñ•

Nous basons notre √©tude sur trois [bases de donn√©es fournies par Walmart relatifs](https://github.com/ettouilebouael/pyspark_for_datascience/raw/refs/heads/main/data/walmart_data.zip) aux ventes des produits dans dix de leur magasins entre janvier 2011 et avril 2016. Ces trois bases sont les suivantes :

- `sell_prices` : contient la liste des produits de chaque magasin ainsi que leur prix associ√© de mani√®re hebdomadaire sous le format suivant :    
```
store_id | item_id | wm_yr_wk | sell_price
```
o√π `wm_yr_wk`correspond √† un num√©ro attribu√© √† une semaine en particulier.

- `calendar` : Pour chaque jour de la p√©riode √† laquelle on s'interesse, indique si un √©v√®nement sp√©cial se produit ou non (superbowl, p√©riode de No√™l, ...). Permet √©galement de lier une semaine donn√©e au num√©ro `wm_yr_wk` et est organis√© comme suit :    
```
date | wm_yr_wk | weekday | wday | month | year | event...
```
- `walmart_sales` : R√©pertorie les ventes journaliaires de chaque produit dans chaque magasin sous le format d√©crit ci-dessous :    
```
item_id | dept_id | cat_id | store_id | state_id | id | date | sales
```

## **Objectifs du projet** üéØ

L'objectif du projet est d'utiliser les bases de donn√©es fournies par Walmart afin de d√©velopper un mod√®le pr√©dictif en PySpark afin d'estimer les ventes mensuelles dans chacun des 10 magasins faisant parti de la cohorte √©tudi√©e. Pour ce faire, nous effectuerons des d√©marches de pr√©paration de donn√©es puis de manipulation de celles-ci afin d'√©tablir le mod√®le le plus performant possible.



## **D√©marches r√©alis√©es** üìì

### Pr√©paration des donn√©es 

Il s'agit ici de parcourir chaque base de donn√©es √† la recherche de valeurs manquantes mais √©galement d'imputer la s√©rie temporelle si des donn√©es manquent au cours d'une ann√©e. La base de donn√©es fournie ne poss√©dait aucune valeur manquante et aucune imputation √©tait n√©cessaire. Les donn√©es pr√©sent√©es √©taient √©galement coh√©rentes, avec absence de valeurs de ventes n√©gatives par exemple, rendant conforme la base de donn√©es sur laquelle nous nous basons.

### Manipulation de la base pour ajouts de features

L'ajout de feature permet au futur mod√®le pr√©dictif d'avoir plus de variables sur lequels se baser afin de pr√©dire les ventes futures au cours des prochains mois. On calcule donc les `lag` et `lead` du nombre de ventes mensuelles pour chaque produit dans chaque magasin.

L'extraction des caract√©ristiques temporelles est √©galement importante, d'o√π le fait d'effectuer un parsing des dates en mois et ann√©e. Pour que la p√©riodicit√© des mois soient plus saisis par le futur mod√®le, nous effectuons un encodage cyclique des mois.

Le calcul des coordonn√©es \( X \) et \( Y \) de chaque mois sur un cercle unit√©, les formules sont les suivantes :

- Soit \( m \) le num√©ro du mois (variant de 1 √† 12).
- La coordonn√©e \( X \) est donn√©e par :

  $$ X = \cos\left( \cfrac{2 \pi \times m}{12} \right) $$

- La coordonn√©e \( Y \) est donn√©e par :

  $$ Y = \sin\left( \cfrac{2 \pi \times m }{12} \right) $$

Le chiffre d'affaire mensuel est quant √† lui calcul√© √† l'aide du prix moyen d'un produit sur un mois multipli√© par son nombre de ventes, respectivement donn√© par les dataframes `sell_prices` et `walmart_sales`. 

Ce chiffre d'affaire est ensuite utilis√© pour le calcul de quotas de march√©, et √©galement r√©alis√© la segmentation ABC des produits.

### Mod√©lisation 

A VENIR

## **Dataframe apr√®s manipulations** üñ•

Le dataframe permettant le d√©veloppement du mod√®le pr√©dictif en PySpark contient, pour chaque mois, produit et magasins les informations suivantes :

- La cat√©gorie auquel le produit appartient `cat_id`
- La r√©gion dans laquelle le magasin se trouve `state_id`
- Le nombre de ventes du produit r√©alis√© pendant ce mois `sales` ainsi que les lag `sales_lag` et lead `sales_lead` de ceux-ci, allant d'une diff√©rence d'un mois √† un an
- Les chiffres d'affaires cumul√©es par produit et cat√©gorie `ca_sum_item`, `ca_sum_category`
- Date de premi√®re commercialisation du produit `first_date`
- Part de march√© d'un produit `marquet_quota`
- La segmentation ABC dans laquelle appartient le produit `perf_category`
  
## **Contact**

- Discord : @praae
- Mail : victor.juille@etudiant.univ-reims.fr
